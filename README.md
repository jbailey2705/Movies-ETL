# Movies-ETL

## Project Overview

Amazing Prime loves the dataset and wants to keep it updated on a daily basis. Within the scope of the Amazing Prime Hackathon, for this profject we will be required to create an automated pipeline that takes in new data from Wikipedia data, Kaggle metadata, and MovieLens rating data. We'll perform the appropriate transformation and load the data into SQL Postgre database.

For this we'll use the following:

1. write an ETL function to read 3 data files
2. extract & transform the Wikipedia data
3. extract & transform the Kaggle and rating data
4. load the data to a PostSQL data base called "movie_data"

## Resources
- Data Sources: [wikipedia-movies.json.zip](https://github.com/jbailey2705/Movies-ETL/files/9668534/wikipedia-movies.json.zip),[movies_metadata.csv.zip](https://github.com/jbailey2705/Movies-ETL/files/9668536/movies_metadata.csv.zip),  c


